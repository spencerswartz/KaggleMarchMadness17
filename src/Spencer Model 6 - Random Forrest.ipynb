{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Model is a random forest - Score= .451502"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from IPython.display import Image\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TeamOverview = pd.read_csv(filepath_or_buffer='../TeamOverview2.csv')\n",
    "TurnyResult = pd.read_csv(filepath_or_buffer='../data\\\\TourneyCompactResults.csv')\n",
    "sampleSub = pd.read_csv('../data\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_train_test(data,split):\n",
    "    np.random.seed(0)\n",
    "    msk = np.random.rand(len(data)) < split\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    return train,test\n",
    "\n",
    "def random_forest(data, features, target,n_estimators, max_depth, min_impurity_split):\n",
    "    model = ensemble.RandomForestClassifier( n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                            random_state=0, min_impurity_split=min_impurity_split)\n",
    "    model = model.fit(data[features],data[target].ravel())\n",
    "    return model\n",
    "\n",
    "def make_predictions(model, data, features):\n",
    "    data.loc[:,'prediction'] = model.predict(data[features])\n",
    "    #dataout['prediction_prob'] = model.predict_proba((data[features]))\n",
    "    return data\n",
    "\n",
    "def find_best_model(train_data,test_data, features, target, max_depth, min_impurity_split, estimators):\n",
    "    best_accuracy=0\n",
    "    best_model=None\n",
    "    for estimate in estimators:\n",
    "        for depth in max_depth:\n",
    "            for impurity in min_impurity_split:\n",
    "                model = random_forest(data=train_data, features=features, target=target,\n",
    "                                      n_estimators=int(estimate), max_depth= depth, min_impurity_split=impurity)\n",
    "                predictions = make_predictions(model, test_data, features)\n",
    "                accuracy = (predictions['prediction']==test_data[target]).mean()\n",
    "                if accuracy>best_accuracy:\n",
    "                    print('depth:',depth,'impurity:',impurity,'trees:',int(estimate),'accuracy:',accuracy)\n",
    "                    best_accuracy=accuracy\n",
    "                    best_model=model\n",
    "    return best_model\n",
    "\n",
    "def model_building_data_generator():\n",
    "    ##Uses TeamOverview\n",
    "    toJoin = TeamOverview[['Season','Team','pointsFor','pointsAgainst',\n",
    "                           'Wins','Losses','Awins','Hwins','Nwins','Hloss',\n",
    "                           'Aloss','Nloss','BestWinWin%','BestWinSeed',\n",
    "                           'AwinAvg','HwinAvg','NwinAvg','HlossAvg','AlossAvg','NlossAvg']]\n",
    "    toJoin['BestWinSeed'].fillna(20, inplace=True)\n",
    "    \n",
    "    Acol =list(toJoin.columns)\n",
    "    x = 0\n",
    "    x = []\n",
    "    for col in Acol:\n",
    "        ocol = 'Away-'+col\n",
    "        x.append(ocol)\n",
    "    AtoJoin = toJoin.copy()\n",
    "    AtoJoin.columns = x\n",
    "    \n",
    "    Hcol =list(toJoin.columns)\n",
    "    y = 0\n",
    "    y = []\n",
    "    for col in Hcol:\n",
    "        ocol = 'Home-'+col\n",
    "        y.append(ocol)\n",
    "    HtoJoin = toJoin.copy()\n",
    "    HtoJoin.columns = y\n",
    "    \n",
    "    ##Uses TurnyResult dataset\n",
    "    TurnyResult.reset_index(inplace = True)\n",
    "    TurnyResult['index'] = TurnyResult['index'].apply(lambda x: x%2)\n",
    "    \n",
    "    WisHome = TurnyResult[TurnyResult['index']==0]\n",
    "    LisHome = TurnyResult[TurnyResult['index']==1]\n",
    "    WisHome['outcome'] = 'H'\n",
    "    LisHome['outcome'] = 'A'\n",
    "    WisHome.drop(['index','Daynum','Wscore','Lscore','Wloc','Numot'], inplace=True, axis=1)\n",
    "    LisHome.drop(['index','Daynum','Wscore','Lscore','Wloc','Numot'], inplace=True, axis=1)\n",
    "    WisHome.columns = ['Season','Hteam','Ateam','outcome']\n",
    "    LisHome.columns = ['Season','Ateam','Hteam','outcome']\n",
    "    \n",
    "    NewTurnyResults = pd.concat([WisHome,LisHome])\n",
    "    NewTurnyResults.columns = ['Away-Team','Home-Team','Season','outcome']\n",
    "    NewTurnyResults = NewTurnyResults.merge(HtoJoin, left_on=['Season','Home-Team'],\n",
    "                                            right_on=['Home-Season','Home-Team'],how='left' )\n",
    "    NewTurnyResults = NewTurnyResults.merge(AtoJoin, left_on=['Season','Away-Team'], \n",
    "                                            right_on=['Away-Season','Away-Team'],how='left' )\n",
    "    NewTurnyResults.drop(['Home-Season','Away-Season'], inplace=True, axis=1)\n",
    "    \n",
    "    train,test = create_train_test(NewTurnyResults, 0.9)\n",
    "    \n",
    "    ##Uses sampeSub\n",
    "    idsplit = sampleSub['id'].str.split('_',expand=True)\n",
    "    idsplit.columns = ['Season','predteam','oteam']\n",
    "    Subtest= sampleSub.join(idsplit)\n",
    "    \n",
    "    Subtest['Season'] = pd.to_numeric(Subtest['Season'])\n",
    "    Subtest['predteam'] = pd.to_numeric(Subtest['predteam'])\n",
    "    Subtest['oteam'] = pd.to_numeric(Subtest['oteam'])\n",
    "    \n",
    "    Subtest = Subtest.merge(HtoJoin, left_on=['Season','oteam'], right_on=['Home-Season','Home-Team'],how='left' )\n",
    "    Subtest = Subtest.merge(AtoJoin, left_on=['Season','predteam'], right_on=['Away-Season','Away-Team'],how='left' )\n",
    "    Subtest.drop(['Home-Season','Away-Season'], inplace=True, axis=1)\n",
    "    \n",
    "    return train, test, Subtest\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify what games would be played in each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = [\n",
    "    'Home-pointsFor',\n",
    "    'Home-pointsAgainst',\n",
    "    'Home-Wins',\n",
    "    'Home-Losses',\n",
    "    'Home-Awins',\n",
    "    'Home-Hwins',\n",
    "    'Home-Nwins',\n",
    "    'Home-Hloss',\n",
    "    'Home-Aloss',\n",
    "    'Home-Nloss',\n",
    "    'Home-BestWinWin%',\n",
    "    'Home-BestWinSeed',\n",
    "    'Home-AwinAvg',\n",
    "    'Home-HwinAvg',\n",
    "    'Home-NwinAvg',\n",
    "#    'Home-HlossAvg',\n",
    "#    'Home-AlossAvg',\n",
    "#    'Home-NlossAvg',\n",
    "    'Away-pointsFor',\n",
    "    'Away-pointsAgainst',\n",
    "    'Away-Wins',\n",
    "    'Away-Losses',\n",
    "    'Away-Awins',\n",
    "    'Away-Hwins',\n",
    "    'Away-Nwins',\n",
    "    'Away-Hloss',\n",
    "    'Away-Aloss',\n",
    "    'Away-Nloss',\n",
    "    'Away-BestWinWin%',\n",
    "    'Away-BestWinSeed',\n",
    "    'Away-AwinAvg',\n",
    "    'Away-HwinAvg',\n",
    "    'Away-NwinAvg',\n",
    "#    'Away-HlossAvg',\n",
    "#    'Away-AlossAvg',\n",
    "#    'Away-NlossAvg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\pandas\\core\\generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>predteam</th>\n",
       "      <th>oteam</th>\n",
       "      <th>Home-Team</th>\n",
       "      <th>Home-pointsFor</th>\n",
       "      <th>Home-pointsAgainst</th>\n",
       "      <th>Home-Wins</th>\n",
       "      <th>Home-Losses</th>\n",
       "      <th>...</th>\n",
       "      <th>Away-Aloss</th>\n",
       "      <th>Away-Nloss</th>\n",
       "      <th>Away-BestWinWin%</th>\n",
       "      <th>Away-BestWinSeed</th>\n",
       "      <th>Away-AwinAvg</th>\n",
       "      <th>Away-HwinAvg</th>\n",
       "      <th>Away-NwinAvg</th>\n",
       "      <th>Away-HlossAvg</th>\n",
       "      <th>Away-AlossAvg</th>\n",
       "      <th>Away-NlossAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_1103_1107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1107</td>\n",
       "      <td>1107</td>\n",
       "      <td>2190</td>\n",
       "      <td>2050</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013_1103_1112</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>2345</td>\n",
       "      <td>2038</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013_1103_1125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125</td>\n",
       "      <td>2307</td>\n",
       "      <td>1939</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013_1103_1129</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>2061</td>\n",
       "      <td>1927</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013_1103_1137</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1137</td>\n",
       "      <td>1137</td>\n",
       "      <td>2152</td>\n",
       "      <td>1846</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  pred  Season  predteam  oteam  Home-Team  Home-pointsFor  \\\n",
       "0  2013_1103_1107   0.5    2013      1103   1107       1107            2190   \n",
       "1  2013_1103_1112   0.5    2013      1103   1112       1112            2345   \n",
       "2  2013_1103_1125   0.5    2013      1103   1125       1125            2307   \n",
       "3  2013_1103_1129   0.5    2013      1103   1129       1129            2061   \n",
       "4  2013_1103_1137   0.5    2013      1103   1137       1137            2152   \n",
       "\n",
       "   Home-pointsAgainst  Home-Wins  Home-Losses      ...        Away-Aloss  \\\n",
       "0                2050         24           10      ...                 4   \n",
       "1                2038         25            7      ...                 4   \n",
       "2                1939         24            6      ...                 4   \n",
       "3                1927         19           10      ...                 4   \n",
       "4                1846         27            5      ...                 4   \n",
       "\n",
       "   Away-Nloss  Away-BestWinWin%  Away-BestWinSeed  Away-AwinAvg  Away-HwinAvg  \\\n",
       "0           1          0.848485              11.0          70.0        74.714   \n",
       "1           1          0.848485              11.0          70.0        74.714   \n",
       "2           1          0.848485              11.0          70.0        74.714   \n",
       "3           1          0.848485              11.0          70.0        74.714   \n",
       "4           1          0.848485              11.0          70.0        74.714   \n",
       "\n",
       "   Away-NwinAvg  Away-HlossAvg  Away-AlossAvg  Away-NlossAvg  \n",
       "0          73.5           64.0          67.75           65.0  \n",
       "1          73.5           64.0          67.75           65.0  \n",
       "2          73.5           64.0          67.75           65.0  \n",
       "3          73.5           64.0          67.75           65.0  \n",
       "4          73.5           64.0          67.75           65.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, modeldata = model_building_data_generator()\n",
    "\n",
    "modeldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Away-Team</th>\n",
       "      <th>Home-Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Home-pointsFor</th>\n",
       "      <th>Home-pointsAgainst</th>\n",
       "      <th>Home-Wins</th>\n",
       "      <th>Home-Losses</th>\n",
       "      <th>Home-Awins</th>\n",
       "      <th>Home-Hwins</th>\n",
       "      <th>...</th>\n",
       "      <th>Away-Aloss</th>\n",
       "      <th>Away-Nloss</th>\n",
       "      <th>Away-BestWinWin%</th>\n",
       "      <th>Away-BestWinSeed</th>\n",
       "      <th>Away-AwinAvg</th>\n",
       "      <th>Away-HwinAvg</th>\n",
       "      <th>Away-NwinAvg</th>\n",
       "      <th>Away-HlossAvg</th>\n",
       "      <th>Away-AlossAvg</th>\n",
       "      <th>Away-NlossAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1112</td>\n",
       "      <td>1104</td>\n",
       "      <td>1985</td>\n",
       "      <td>H</td>\n",
       "      <td>2055</td>\n",
       "      <td>1821</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.429</td>\n",
       "      <td>70.182</td>\n",
       "      <td>70.429</td>\n",
       "      <td>60.667</td>\n",
       "      <td>55.200</td>\n",
       "      <td>73.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1305</td>\n",
       "      <td>1301</td>\n",
       "      <td>1985</td>\n",
       "      <td>H</td>\n",
       "      <td>2146</td>\n",
       "      <td>1893</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>83.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>68.625</td>\n",
       "      <td>68.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1433</td>\n",
       "      <td>1104</td>\n",
       "      <td>1985</td>\n",
       "      <td>H</td>\n",
       "      <td>2055</td>\n",
       "      <td>1821</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.222</td>\n",
       "      <td>73.750</td>\n",
       "      <td>81.250</td>\n",
       "      <td>58.000</td>\n",
       "      <td>63.750</td>\n",
       "      <td>63.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1246</td>\n",
       "      <td>1385</td>\n",
       "      <td>1985</td>\n",
       "      <td>H</td>\n",
       "      <td>2284</td>\n",
       "      <td>1932</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>62.500</td>\n",
       "      <td>67.273</td>\n",
       "      <td>92.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>64.250</td>\n",
       "      <td>55.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1239</td>\n",
       "      <td>1396</td>\n",
       "      <td>1986</td>\n",
       "      <td>H</td>\n",
       "      <td>1992</td>\n",
       "      <td>1682</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.833</td>\n",
       "      <td>72.300</td>\n",
       "      <td>63.333</td>\n",
       "      <td>61.667</td>\n",
       "      <td>61.500</td>\n",
       "      <td>61.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Away-Team  Home-Team  Season outcome  Home-pointsFor  Home-pointsAgainst  \\\n",
       "8        1112       1104    1985       H            2055                1821   \n",
       "13       1305       1301    1985       H            2146                1893   \n",
       "20       1433       1104    1985       H            2055                1821   \n",
       "27       1246       1385    1985       H            2284                1932   \n",
       "38       1239       1396    1986       H            1992                1682   \n",
       "\n",
       "    Home-Wins  Home-Losses  Home-Awins  Home-Hwins      ...        Away-Aloss  \\\n",
       "8          21            9           5          15      ...                 5   \n",
       "13         20            9           4          14      ...                 8   \n",
       "20         21            9           5          15      ...                 4   \n",
       "27         27            3           7          12      ...                 8   \n",
       "38         24            5          12          10      ...                 6   \n",
       "\n",
       "    Away-Nloss  Away-BestWinWin%  Away-BestWinSeed  Away-AwinAvg  \\\n",
       "8            1          0.758621               6.0        70.429   \n",
       "13           0          0.900000               4.0        83.000   \n",
       "20           0          0.733333               7.0        72.222   \n",
       "27           1          0.766667               3.0        62.500   \n",
       "38           0          0.740741               8.0        68.833   \n",
       "\n",
       "    Away-HwinAvg  Away-NwinAvg  Away-HlossAvg  Away-AlossAvg  Away-NlossAvg  \n",
       "8         70.182        70.429         60.667         55.200         73.000  \n",
       "13        82.000        81.000         74.000         68.625         68.625  \n",
       "20        73.750        81.250         58.000         63.750         63.750  \n",
       "27        67.273        92.000         62.000         64.250         55.000  \n",
       "38        72.300        63.333         61.667         61.500         61.500  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100.,  200.,  300.,  400.,  500.,  600.,  700.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthset = np.linspace(3,17,15)\n",
    "impurityset = np.linspace(.05,.20,10)\n",
    "esti = np.linspace(100,700,7)\n",
    "esti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 3.0 impurity: 0.05 trees: 100 accuracy: 0.719827586207\n",
      "depth: 3.0 impurity: 0.1 trees: 100 accuracy: 0.724137931034\n",
      "depth: 4.0 impurity: 0.05 trees: 100 accuracy: 0.728448275862\n",
      "depth: 6.0 impurity: 0.1 trees: 100 accuracy: 0.737068965517\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bestmodel = find_best_model(train_data=train,test_data=test, \n",
    "                            features=feats, target='outcome', max_depth= depthset,\n",
    "                            min_impurity_split = impurityset, estimators=esti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_prob = bestmodel.predict_proba(modeldata[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict.to_csv('../submissions\\\\Fithsub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Quick Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''model = ensemble.RandomForestClassifier( n_estimators=1000, max_depth=13,\n",
    "                                            random_state=0, min_impurity_split=.11666666667)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())\n",
    "prediction_prob = model.predict_proba(modeldata[feats])\n",
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "predict.to_csv('../submissions\\\\Thirdsub.csv',index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-02cff6fbb618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = ensemble.RandomForestClassifier( n_estimators=100, max_depth=5,\n\u001b[1;32m      2\u001b[0m                                         random_state=0, min_impurity_split=.2)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outcome'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\envs\\py35\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier( n_estimators=100, max_depth=5,\n",
    "                                        random_state=0, min_impurity_split=.2)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Model is a random forest - Score= .451502"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from IPython.display import Image\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TeamOverview = pd.read_csv(filepath_or_buffer='../TeamOverview2.csv')\n",
    "TurnyResult = pd.read_csv(filepath_or_buffer='../data\\\\TourneyCompactResults.csv')\n",
    "sampleSub = pd.read_csv('../data\\\\sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_train_test(data,split):\n",
    "    np.random.seed(0)\n",
    "    msk = np.random.rand(len(data)) < split\n",
    "    train = data[msk]\n",
    "    test = data[~msk]\n",
    "    return train,test\n",
    "\n",
    "def random_forest(data, features, target,n_estimators, max_depth, min_impurity_split):\n",
    "    model = ensemble.RandomForestClassifier( n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                            random_state=0, min_impurity_split=min_impurity_split)\n",
    "    model = model.fit(data[features],data[target].ravel())\n",
    "    return model\n",
    "\n",
    "def make_predictions(model, data, features):\n",
    "    data.loc[:,'prediction'] = model.predict(data[features])\n",
    "    #dataout['prediction_prob'] = model.predict_proba((data[features]))\n",
    "    return data\n",
    "\n",
    "def find_best_model(train_data,test_data, features, target, max_depth, min_impurity_split, estimators):\n",
    "    best_accuracy=0\n",
    "    best_model=None\n",
    "    for estimate in estimators:\n",
    "        for depth in max_depth:\n",
    "            for impurity in min_impurity_split:\n",
    "                model = model.fit(train[feats],train['outcome'].ravel())\n",
    "                predictions = make_predictions(model, test_data, features)\n",
    "                accuracy = (predictions['prediction']==test_data[target]).mean()\n",
    "                if accuracy>best_accuracy:\n",
    "                    print('depth:',depth,'impurity:',impurity,'trees:',int(estimate),'accuracy:',accuracy)\n",
    "                    best_accuracy=accuracy\n",
    "                    best_model=model\n",
    "    return best_model\n",
    "\n",
    "def model_building_data_generator():\n",
    "    ##Uses TeamOverview\n",
    "    toJoin = TeamOverview[['Season','Team','pointsFor','pointsAgainst',\n",
    "                           'Wins','Losses','Awins','Hwins','Nwins','Hloss',\n",
    "                           'Aloss','Nloss','BestWinWin%','BestWinSeed',\n",
    "                           'AwinAvg','HwinAvg','NwinAvg','HlossAvg','AlossAvg','NlossAvg']]\n",
    "    toJoin['BestWinSeed'].fillna(20, inplace=True)\n",
    "    \n",
    "    Acol =list(toJoin.columns)\n",
    "    x = 0\n",
    "    x = []\n",
    "    for col in Acol:\n",
    "        ocol = 'Away-'+col\n",
    "        x.append(ocol)\n",
    "    AtoJoin = toJoin.copy()\n",
    "    AtoJoin.columns = x\n",
    "    \n",
    "    Hcol =list(toJoin.columns)\n",
    "    y = 0\n",
    "    y = []\n",
    "    for col in Hcol:\n",
    "        ocol = 'Home-'+col\n",
    "        y.append(ocol)\n",
    "    HtoJoin = toJoin.copy()\n",
    "    HtoJoin.columns = y\n",
    "    \n",
    "    ##Uses TurnyResult dataset\n",
    "    TurnyResult.reset_index(inplace = True)\n",
    "    TurnyResult['index'] = TurnyResult['index'].apply(lambda x: x%2)\n",
    "    \n",
    "    WisHome = TurnyResult[TurnyResult['index']==0]\n",
    "    LisHome = TurnyResult[TurnyResult['index']==1]\n",
    "    WisHome['outcome'] = 'H'\n",
    "    LisHome['outcome'] = 'A'\n",
    "    WisHome.drop(['index','Daynum','Wscore','Lscore','Wloc','Numot'], inplace=True, axis=1)\n",
    "    LisHome.drop(['index','Daynum','Wscore','Lscore','Wloc','Numot'], inplace=True, axis=1)\n",
    "    WisHome.columns = ['Season','Hteam','Ateam','outcome']\n",
    "    LisHome.columns = ['Season','Ateam','Hteam','outcome']\n",
    "    \n",
    "    NewTurnyResults = pd.concat([WisHome,LisHome])\n",
    "    NewTurnyResults.columns = ['Away-Team','Home-Team','Season','outcome']\n",
    "    NewTurnyResults = NewTurnyResults.merge(HtoJoin, left_on=['Season','Home-Team'],\n",
    "                                            right_on=['Home-Season','Home-Team'],how='left' )\n",
    "    NewTurnyResults = NewTurnyResults.merge(AtoJoin, left_on=['Season','Away-Team'], \n",
    "                                            right_on=['Away-Season','Away-Team'],how='left' )\n",
    "    NewTurnyResults.drop(['Home-Season','Away-Season'], inplace=True, axis=1)\n",
    "    \n",
    "    train,test = create_train_test(NewTurnyResults, 0.9)\n",
    "    \n",
    "    ##Uses sampeSub\n",
    "    idsplit = sampleSub['id'].str.split('_',expand=True)\n",
    "    idsplit.columns = ['Season','predteam','oteam']\n",
    "    Subtest= sampleSub.join(idsplit)\n",
    "    \n",
    "    Subtest['Season'] = pd.to_numeric(Subtest['Season'])\n",
    "    Subtest['predteam'] = pd.to_numeric(Subtest['predteam'])\n",
    "    Subtest['oteam'] = pd.to_numeric(Subtest['oteam'])\n",
    "    \n",
    "    Subtest = Subtest.merge(HtoJoin, left_on=['Season','oteam'], right_on=['Home-Season','Home-Team'],how='left' )\n",
    "    Subtest = Subtest.merge(AtoJoin, left_on=['Season','predteam'], right_on=['Away-Season','Away-Team'],how='left' )\n",
    "    Subtest.drop(['Home-Season','Away-Season'], inplace=True, axis=1)\n",
    "    \n",
    "    return train, test, Subtest\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify what games would be played in each round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = [\n",
    "    'Home-pointsFor',\n",
    "    'Home-pointsAgainst',\n",
    "    'Home-Wins',\n",
    "    'Home-Losses',\n",
    "    'Home-Awins',\n",
    "    'Home-Hwins',\n",
    "    'Home-Nwins',\n",
    "    'Home-Hloss',\n",
    "    'Home-Aloss',\n",
    "    'Home-Nloss',\n",
    "    'Home-BestWinWin%',\n",
    "    'Home-BestWinSeed',\n",
    "    'Home-AwinAvg',\n",
    "    'Home-HwinAvg',\n",
    "    'Home-NwinAvg',\n",
    "\n",
    "    'Away-pointsFor',\n",
    "    'Away-pointsAgainst',\n",
    "    'Away-Wins',\n",
    "    'Away-Losses',\n",
    "    'Away-Awins',\n",
    "    'Away-Hwins',\n",
    "    'Away-Nwins',\n",
    "    'Away-Hloss',\n",
    "    'Away-Aloss',\n",
    "    'Away-Nloss',\n",
    "    'Away-BestWinWin%',\n",
    "    'Away-BestWinSeed',\n",
    "    'Away-AwinAvg',\n",
    "    'Away-HwinAvg',\n",
    "    'Away-NwinAvg',\n",
    "\n",
    "    'SeedDifH-A'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>SeedNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>1102</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>1103</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>1104</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>1106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>1108</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Team  SeedNum\n",
       "0    1985  1102      NaN\n",
       "1    1985  1103      NaN\n",
       "2    1985  1104      7.0\n",
       "3    1985  1106      NaN\n",
       "4    1985  1108      NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = TeamOverview[['Season','Team','SeedNum']]\n",
    "seed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\pandas\\core\\generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>predteam</th>\n",
       "      <th>oteam</th>\n",
       "      <th>Home-Team</th>\n",
       "      <th>Home-pointsFor</th>\n",
       "      <th>Home-pointsAgainst</th>\n",
       "      <th>Home-Wins</th>\n",
       "      <th>Home-Losses</th>\n",
       "      <th>...</th>\n",
       "      <th>Away-Aloss</th>\n",
       "      <th>Away-Nloss</th>\n",
       "      <th>Away-BestWinWin%</th>\n",
       "      <th>Away-BestWinSeed</th>\n",
       "      <th>Away-AwinAvg</th>\n",
       "      <th>Away-HwinAvg</th>\n",
       "      <th>Away-NwinAvg</th>\n",
       "      <th>Away-HlossAvg</th>\n",
       "      <th>Away-AlossAvg</th>\n",
       "      <th>Away-NlossAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_1103_1107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1107</td>\n",
       "      <td>1107</td>\n",
       "      <td>2190</td>\n",
       "      <td>2050</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013_1103_1112</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1112</td>\n",
       "      <td>1112</td>\n",
       "      <td>2345</td>\n",
       "      <td>2038</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013_1103_1125</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1125</td>\n",
       "      <td>1125</td>\n",
       "      <td>2307</td>\n",
       "      <td>1939</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013_1103_1129</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1129</td>\n",
       "      <td>1129</td>\n",
       "      <td>2061</td>\n",
       "      <td>1927</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013_1103_1137</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>1103</td>\n",
       "      <td>1137</td>\n",
       "      <td>1137</td>\n",
       "      <td>2152</td>\n",
       "      <td>1846</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.714</td>\n",
       "      <td>73.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>67.75</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  pred  Season  predteam  oteam  Home-Team  Home-pointsFor  \\\n",
       "0  2013_1103_1107   0.5    2013      1103   1107       1107            2190   \n",
       "1  2013_1103_1112   0.5    2013      1103   1112       1112            2345   \n",
       "2  2013_1103_1125   0.5    2013      1103   1125       1125            2307   \n",
       "3  2013_1103_1129   0.5    2013      1103   1129       1129            2061   \n",
       "4  2013_1103_1137   0.5    2013      1103   1137       1137            2152   \n",
       "\n",
       "   Home-pointsAgainst  Home-Wins  Home-Losses      ...        Away-Aloss  \\\n",
       "0                2050         24           10      ...                 4   \n",
       "1                2038         25            7      ...                 4   \n",
       "2                1939         24            6      ...                 4   \n",
       "3                1927         19           10      ...                 4   \n",
       "4                1846         27            5      ...                 4   \n",
       "\n",
       "   Away-Nloss  Away-BestWinWin%  Away-BestWinSeed  Away-AwinAvg  Away-HwinAvg  \\\n",
       "0           1          0.848485              11.0          70.0        74.714   \n",
       "1           1          0.848485              11.0          70.0        74.714   \n",
       "2           1          0.848485              11.0          70.0        74.714   \n",
       "3           1          0.848485              11.0          70.0        74.714   \n",
       "4           1          0.848485              11.0          70.0        74.714   \n",
       "\n",
       "   Away-NwinAvg  Away-HlossAvg  Away-AlossAvg  Away-NlossAvg  \n",
       "0          73.5           64.0          67.75           65.0  \n",
       "1          73.5           64.0          67.75           65.0  \n",
       "2          73.5           64.0          67.75           65.0  \n",
       "3          73.5           64.0          67.75           65.0  \n",
       "4          73.5           64.0          67.75           65.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test, modeldata = model_building_data_generator()\n",
    "\n",
    "modeldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.merge(seed, left_on=['Season','Home-Team'], right_on=['Season','Team'], how='left')\\\n",
    ".merge(seed, left_on=['Season','Away-Team'], right_on=['Season','Team'], how='left')\n",
    "train['SeedDifH-A'] = train['SeedNum_x']-train['SeedNum_x']\n",
    "train.drop(['Team_x','SeedNum_x','Team_y','SeedNum_y'], inplace=True, axis=1)\n",
    "\n",
    "test = test.merge(seed, left_on=['Season','Home-Team'], right_on=['Season','Team'], how='left')\\\n",
    ".merge(seed, left_on=['Season','Away-Team'], right_on=['Season','Team'], how='left')\n",
    "test['SeedDifH-A'] = test['SeedNum_x']-test['SeedNum_x']\n",
    "test.drop(['Team_x','SeedNum_x','Team_y','SeedNum_y'], inplace=True, axis=1)\n",
    "\n",
    "modeldata = modeldata.merge(seed, left_on=['Season','Home-Team'], right_on=['Season','Team'], how='left')\\\n",
    ".merge(seed, left_on=['Season','Away-Team'], right_on=['Season','Team'], how='left')\n",
    "modeldata['SeedDifH-A'] = modeldata['SeedNum_x']-modeldata['SeedNum_x']\n",
    "modeldata.drop(['Team_x','SeedNum_x','Team_y','SeedNum_y'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "#train = , test, modeldata\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100.,  200.,  300.,  400.,  500.,  600.,  700.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthset = np.linspace(3,17,15)\n",
    "impurityset = np.linspace(.05,.20,10)\n",
    "esti = np.linspace(100,700,7)\n",
    "esti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 3.0 impurity: 0.05 trees: 100 accuracy: 0.706896551724\n",
      "depth: 3.0 impurity: 0.0666666666667 trees: 100 accuracy: 0.711206896552\n",
      "depth: 6.0 impurity: 0.0666666666667 trees: 100 accuracy: 0.724137931034\n",
      "depth: 9.0 impurity: 0.15 trees: 100 accuracy: 0.745689655172\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bestmodel = find_best_model(train_data=train,test_data=test, \n",
    "                            features=feats, target='outcome', max_depth= depthset,\n",
    "                            min_impurity_split = impurityset, estimators=esti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_prob = bestmodel.predict_proba(modeldata[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65786519,  0.34213481],\n",
       "       [ 0.44187893,  0.55812107],\n",
       "       [ 0.50529313,  0.49470687],\n",
       "       ..., \n",
       "       [ 0.1965955 ,  0.8034045 ],\n",
       "       [ 0.53617468,  0.46382532],\n",
       "       [ 0.8313417 ,  0.1686583 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_1103_1107</td>\n",
       "      <td>0.657865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013_1103_1112</td>\n",
       "      <td>0.441879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013_1103_1125</td>\n",
       "      <td>0.505293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013_1103_1129</td>\n",
       "      <td>0.699085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013_1103_1137</td>\n",
       "      <td>0.609039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      pred\n",
       "0  2013_1103_1107  0.657865\n",
       "1  2013_1103_1112  0.441879\n",
       "2  2013_1103_1125  0.505293\n",
       "3  2013_1103_1129  0.699085\n",
       "4  2013_1103_1137  0.609039"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict.to_csv('../submissions\\\\7sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Quick Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = ensemble.RandomForestClassifier( n_estimators=1000, max_depth=13,\\n                                            random_state=0, min_impurity_split=.11666666667)\\nmodel = model.fit(train[feats],train['outcome'].ravel())\\nprediction_prob = model.predict_proba(modeldata[feats])\\npredict = pd.DataFrame(prediction_prob)\\npredict['id']=modeldata['id']\\npredict.drop(1,axis=1, inplace=True)\\npredict.columns = ['pred','id']\\npredict = predict[['id','pred']]\\npredict.to_csv('../submissions\\\\Thirdsub.csv',index=False)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = ensemble.RandomForestClassifier( n_estimators=1000, max_depth=13,\n",
    "                                            random_state=0, min_impurity_split=.11666666667)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())\n",
    "prediction_prob = model.predict_proba(modeldata[feats])\n",
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "predict.to_csv('../submissions\\\\Thirdsub.csv',index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier( n_estimators=1000,\n",
    "                                            random_state=0)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction_prob = model.predict(test[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70258620689655171"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(prediction_prob==test['outcome']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_prob = model.predict_proba(modeldata[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_1103_1107</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013_1103_1112</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013_1103_1125</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013_1103_1129</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013_1103_1137</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id   pred\n",
       "0  2013_1103_1107  0.709\n",
       "1  2013_1103_1112  0.437\n",
       "2  2013_1103_1125  0.482\n",
       "3  2013_1103_1129  0.709\n",
       "4  2013_1103_1137  0.652"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict.to_csv('../submissions\\\\8sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693965517241\n",
      "               id    pred\n",
      "0  2013_1103_1107  0.7097\n",
      "1  2013_1103_1112  0.4232\n",
      "2  2013_1103_1125  0.4813\n",
      "3  2013_1103_1129  0.7069\n",
      "4  2013_1103_1137  0.6736\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier( n_estimators=10000,\n",
    "                                            random_state=0)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())\n",
    "prediction_prob = model.predict(test[feats])\n",
    "print((prediction_prob==test['outcome']).mean())\n",
    "prediction_prob = model.predict_proba(modeldata[feats])\n",
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "print(predict.head())\n",
    "predict.to_csv('../submissions\\\\9sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702586206897\n",
      "               id     pred\n",
      "0  2013_1103_1107  0.71040\n",
      "1  2013_1103_1112  0.41935\n",
      "2  2013_1103_1125  0.47925\n",
      "3  2013_1103_1129  0.70595\n",
      "4  2013_1103_1137  0.67460\n"
     ]
    }
   ],
   "source": [
    "model = ensemble.RandomForestClassifier( n_estimators=20000,\n",
    "                                            random_state=0)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())\n",
    "prediction_prob = model.predict(test[feats])\n",
    "print((prediction_prob==test['outcome']).mean())\n",
    "prediction_prob = model.predict_proba(modeldata[feats])\n",
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "print(predict.head())\n",
    "predict.to_csv('../submissions\\\\10sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier( n_estimators=100000,\n",
    "                                            random_state=0, max_depth = 1)\n",
    "model = model.fit(train[feats],train['outcome'].ravel())\n",
    "prediction_prob = model.predict(test[feats])\n",
    "print((prediction_prob==test['outcome']).mean())\n",
    "prediction_prob = model.predict_proba(modeldata[feats])\n",
    "predict = pd.DataFrame(prediction_prob)\n",
    "predict['id']=modeldata['id']\n",
    "predict.drop(1,axis=1, inplace=True)\n",
    "predict.columns = ['pred','id']\n",
    "predict = predict[['id','pred']]\n",
    "print(predict.head())\n",
    "predict.to_csv('../submissions\\\\12sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
